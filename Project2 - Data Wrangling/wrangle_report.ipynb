{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues Identified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues\n",
    "\n",
    "Quality issues refers to issues that affect data suitability. It ranages from missing data, inaccurate data etc.\n",
    "\n",
    "In my data wrangling process, 8 data quality issues were identified and resolved as outlined below:\n",
    "\n",
    "1. df_img_prediction remove underscore on dog prediction names columns [p1, p2 and p3]\n",
    "\n",
    "To standardize the dog breeds in the image prediction table, the columns p1, p2 and p3 are dog breed prediction in the order p1 - highest probability and p3 being lowest probability.\n",
    "\n",
    "Whenever the dog breed has two words, the data has these values concatenated with underscore between them. In this stage, the undercore was removed.\n",
    "\n",
    "2. df_img_prediction Capitalize the first character on dog prediction names columns [p1, p2 and p3]\n",
    "\n",
    "Data cleanup performed in this stage is building up on the steps highlighted above.\n",
    "\n",
    "From the data, the dog breeds in columns p1, p2 and p3 have mixed case with some starting with Uppercase while others are all in lowercase.\n",
    "\n",
    "In this step, `capitilize` function was used to ensure all data in these columns have uniform case.\n",
    "\n",
    "3. Use mean rate to recalculate rating_numerator when value is greater than 15\n",
    "\n",
    "The maximum `rating_numerator` given to a dog is 15. Our data had occurrances where data in this column was greater than 15.\n",
    "\n",
    "To ensure that the maximum rating that is available in the data is equal to or less than 15, an average value for data having less than 15 was calculated and this value was used to replace values greater than 15.\n",
    "\n",
    "4. df_img_prediction and df_twitter_arch change tweet_id datatype from int to string also id in json_tweets\n",
    "\n",
    "`tweet_id` also referred to `id` in `json_tweets` table has integer as its datatype.\n",
    "\n",
    "To be able to perform analysis on this data, the datatypes for this column is changed to string in all the tables\n",
    "\n",
    "5. df_twitter_arch change [timestamp, retweeted_status_timestamp] datatype from string to datetime\n",
    "\n",
    "`timestamp` and `retweeted_status_timestamp` in the `twitter_arch` table has its datatype as object. To be able to perform time series analysis on this data has datetime datatype needs to be used.\n",
    "\n",
    "6. df_twitter_arch denominator having values greater than 10. The denominator should always be 10.\n",
    "\n",
    "From the weratedogs Wikipedia page, dogs are rated out of 10, which is the denominator.\n",
    "\n",
    "The twitter archive data has some records which have denominator greater than 10. For this case, these values were replaced with 10.\n",
    "\n",
    "7. Rename json_tweets.id to json_tweets.tweet_id to be same to other 2 tables\n",
    "\n",
    "On `json_tweets` table, `tweet_id` is named `id`. To ensure easy join on tidiness cleaning, this column was renamed to `tweet_id`\n",
    "\n",
    "8. Remove tweets that are Retweets and replies\n",
    "\n",
    "Twitter archive table has tweets in the category of original, retweet and replies. For this analysis, we are only interested on original tweets.\n",
    "\n",
    "retweet and replies tweets were dropped at this stage\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tidiness Issues\n",
    "\n",
    "1. `json_tweets` extract source text from source url\n",
    "\n",
    "Tweets source is contained in url `a href` tag under the anchor section.\n",
    "\n",
    "Regular expression was used to extract this information. This column could have been split into url and source name.\n",
    "For this analysis, url was not required and was thus skipped\n",
    "\n",
    "2. Combine all three tables into one table\n",
    "\n",
    "To ensure that tweets data are collated in one location. All the data from different sources were joined together by use of `pd.merge` function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
